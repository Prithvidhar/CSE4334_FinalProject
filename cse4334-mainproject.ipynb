{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\n#References from documentation\ntrans = torchvision.transforms.Compose([\n    torchvision.transforms.RandAugment(),\n    torchvision.transforms.Resize(size =(512,512)),\n    ToTensor()\n])\nbatchS = 70\ndata = torchvision.datasets.ImageFolder('../input/wild-animals/Wild_animals_512',transform = trans)\ntrain_data,test_data = torch.utils.data.random_split(data,[round(data.__len__()*0.6),round(data.__len__()*0.4)])\n\n#valid_data,testy_data = torch.utils.data.random_split(test_data,[round(test_data.__len__()*0.5),round(test_data.__len__()*0.5)])\nvalid_data,testy_data = torch.utils.data.random_split(test_data,[345,344])\ntrain_load = DataLoader(train_data,shuffle = True,batch_size= batchS,drop_last=True)\nvalid_load = DataLoader(valid_data,shuffle = True,batch_size= batchS,drop_last = True)\ntest_load = DataLoader(testy_data,shuffle = True,batch_size= batchS,drop_last = True)\n# print(len(test_load.dataset))\n\nprint('done')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-15T02:12:32.540723Z","iopub.execute_input":"2022-11-15T02:12:32.541445Z","iopub.status.idle":"2022-11-15T02:12:32.576109Z","shell.execute_reply.started":"2022-11-15T02:12:32.541399Z","shell.execute_reply":"2022-11-15T02:12:32.575030Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"done\n","output_type":"stream"}]},{"cell_type":"code","source":"#Neural Network referenced from  https://pytorch.org/tutorials/beginner/examples_nn/polynomial_module.html\n%matplotlib inline\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\n\n#Initial Model code referenced from https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n#Code from the 'Define the Network' section\n#Experiment 1\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        #Feature extraction\n        self.conv= nn.Conv2d(3,64,9)\n        self.conv2 = nn.Conv2d(64,128,5)\n        self.conv3 = nn.Conv2d(128,256,5)\n        self.conv4 = nn.Conv2d(256,512,5)\n        self.bat2d1 = nn.BatchNorm2d(64)\n        self.bat2d2 = nn.BatchNorm2d(128)\n        self.bat2d3 = nn.BatchNorm2d(256)\n        self.bat2d4 = nn.BatchNorm2d(512)\n        self.bat1d = nn.BatchNorm1d(196)\n        self.dropout = nn.Dropout(p= 0.5)\n\n        \n        #Classification layer\n        self.lin = nn.Linear(921600,196)\n        self.lin2 = nn.Linear(196,6)\n        \n    def forward(self,x):\n        #First two lines are referenced\n        x = F.max_pool2d(F.relu(self.conv(x)),(2,2))\n        x=self.bat2d1(x)\n        self.dropout(x)\n        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n        x=self.bat2d2(x)\n        self.dropout(x)\n        x = F.max_pool2d(F.relu(self.conv3(x)),(2,2))\n        x=self.bat2d3(x)\n        self.dropout(x)\n        x=self.bat2d4(x)\n        self.dropout(x)\n        #print(x.shape)\n        #Flattening tensors\n        x = torch.flatten(x,1)\n#         print(x.shape)\n        x = F.relu(self.lin(x))\n        self.bat1d(x)\n        x = F.softmax(self.lin2(x),dim = 1)\n        return x\n    \nmodel = Model()\ndevice = torch.device(\"cuda:0\")\n#model.to(torch.device(\"cuda:0\"))\nif torch.cuda.device_count() > 1:\n    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n    model = nn.DataParallel(model)\n\nmodel.to(device)\noptimizer = optim.SGD(model.parameters(), lr = 0.001,weight_decay=0.000001)\nlossfn = nn.CrossEntropyLoss()\nlossx = 0\nlossxt = 0\n\n#count = []\nlossgraph = []\ntestgraph = []\n#Code referenced from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n#I extracted data from the DataLoaders following the tutorial above\n#I used two for loops and called the optimizer and loss functions in a similar way\n#From the 'Define the network' section of the webpage.\nfor epoch in range(100):\n\n    \n    for i,data in enumerate(train_load, 0):\n        lossx = 0\n        pics, label = data\n        pics, label = pics.cuda(), label.cuda()\n        #print(pics.shape)\n        optimizer.zero_grad()\n        output = model(pics)\n        #reshaping label\n        #label = torch.tensor(label)\n        labely = torch.zeros(batchS,6)\n        for j in range(batchS):\n            labely[j][label[j]] = 1\n        #print(output)\n        labely = labely.cuda()\n        loss = lossfn(output,labely)\n        #lossgraph.append(loss)\n        loss.backward()\n        lossx += loss\n        #print(output)\n        optimizer.step()\n        #graphing loss\n        \n        #print(len(lossgraph),epoch,i)\n    lossgraph.append(lossx.item())\n\n    testingloss = nn.CrossEntropyLoss()\n#     classes = {0:'Motorbikes',1:'Airplanes',2:'Schooner'}\n    total = 0\n    correct = 0\n    for i, data in enumerate(valid_load,0):\n        lossxt = 0\n        pics,label = data\n        pics, label = pics.cuda(), label.cuda()\n        #print(pics.shape)\n        output = model(pics)\n        labely = torch.zeros(batchS,6)\n        for j in range(batchS):\n            labely[j][label[j]] = 1\n            #print(output)\n        labely = labely.cuda()\n        loss = testingloss(output,labely)\n        lossxt += loss.item()\n        #print(output)\n        maxele,maxindx = torch.max(output,1)\n        for j in range(batchS):\n            #print('Prediction: {0}, Answer: {1}'.format(classes[maxindx[j].item()],classes[label[j].item()]))\n            #print(maxindx[j].item(),label[j].item())\n            if(torch.eq(maxindx[j],label[j])):\n                correct = correct +1\n            total = total+1\n    #print(correct,total)\n    \n    #plt.legend('Training set','Validation set')\n    accuracy = (correct/total)*100\n    #print('Accuracy is {0:.2f}%'.format(accuracy))\n    testgraph.append(lossxt)\n\n        #plt.ylim(4e-1,7e-1)\n#plt.yscale('log')\n#plt.figure(figsize = (1,1))\n#print(testgraph)\n\n#plt.yscale('log')\n\n\n\ntorch.cuda.empty_cache()\n        \n        \n    \n\n\n\n    \n#for epoch,data in enumerate(train_load,0):\n    #inputy, label= data\n    #forward(inputy)\n#ask how to get gradient of linear stuff and how to determine convolutions","metadata":{"execution":{"iopub.status.busy":"2022-11-15T02:12:32.578105Z","iopub.execute_input":"2022-11-15T02:12:32.578443Z","iopub.status.idle":"2022-11-15T02:12:34.373660Z","shell.execute_reply.started":"2022-11-15T02:12:32.578407Z","shell.execute_reply":"2022-11-15T02:12:34.371861Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1825/271149621.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#model.to(torch.device(\"cuda:0\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_1825/271149621.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#Classification layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m921600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m196\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m196\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# https://github.com/pytorch/pytorch/issues/57109\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"plt.yscale('log')\nplt.plot(testgraph,'r-')\nplt.plot(lossgraph)","metadata":{"execution":{"iopub.status.busy":"2022-11-15T02:12:34.375085Z","iopub.status.idle":"2022-11-15T02:12:34.375913Z","shell.execute_reply.started":"2022-11-15T02:12:34.375580Z","shell.execute_reply":"2022-11-15T02:12:34.375626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#validation cell\n#Code referenced from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n#I extracted data from the DataLoaders following the tutorial above\n#I used two for loops and called the optimizer and loss functions in a similar way\n#From the 'Define the network' section of the webpage.\n'''\n\n'''\n#testgraph = []\n#testingloss = nn.CrossEntropyLoss()\nclasses = {0:'Motorbikes',1:'Airplanes',2:'Schooner'}\ntotal = 0\ncorrect = 0\ncl = []\npl = []\nfor i, data in enumerate(valid_load,0):\n    lossxt = 0\n    pics,label = data\n    pics, label = pics.cuda(), label.cuda()\n    #print(pics.shape)\n    output = model(pics)\n    labely = torch.zeros(batchS,6)\n    for j in range(batchS):\n        labely[j][label[j]] = 1\n        #print(output)\n    labely = labely.cuda()\n    #loss = testingloss(output,labely)\n    #lossxt += loss.item()\n    #print(output)\n    maxele,maxindx = torch.max(output,1)\n    #testgraph.append(lossxt)\n    for j in range(batchS):\n        #print('Prediction: {0}, Answer: {1}'.format(classes[maxindx[j].item()],classes[label[j].item()]))\n        #print(maxindx[j].item(),label[j].item())\n        cl.append(label[j].item())\n        pl.append(maxindx[j].item())\n        if(torch.eq(maxindx[j],label[j])):\n            correct = correct +1\n        total = total+1\nprint(correct,total)\n#plt.plot(testgraph)\n#plt.legend('Training set','Validation set')\naccuracy = (correct/total)*100\nfscore = f1_score(cl,pl,average='macro')\nprint(\"F1 score is {0:.2f}\".format(fscore))\nprint('Accuracy is {0:.2f}%'.format(accuracy))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-15T02:12:34.377398Z","iopub.status.idle":"2022-11-15T02:12:34.378142Z","shell.execute_reply.started":"2022-11-15T02:12:34.377869Z","shell.execute_reply":"2022-11-15T02:12:34.377894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing data\n#Code referenced from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n#I extracted data from the DataLoaders following the tutorial above\n#I used two for loops and called the optimizer and loss functions in a similar way.\n#From the 'Define the network' section of the webpage.\ntotal = 0\ncorrect =0\ncl2 = []\npl2 = []\nfor i2, data2 in enumerate(test_load,0):\n    #lossxt = 0\n    pics,label = data2\n    pics, label = pics.cuda(), label.cuda()\n    #print(pics.shape)\n    output = model(pics)\n    labely = torch.zeros(batchS,3)\n    for j in range(batchS):\n        labely[j][label[j]] = 1\n        #print(output)\n    labely = labely.cuda()\n    loss = testingloss(output,labely)\n    #lossxt += loss\n    #print(output)\n    maxele,maxindx = torch.max(output,1)\n    #testgraph.append(lossxt)\n    for j in range(batchS):\n        #print('Prediction: {0}, Answer: {1}'.format(classes[maxindx[j].item()],classes[label[j].item()]))\n        #print(maxindx[j].item(),label[j].item())\n        cl2.append(label[j].item())\n        pl2.append(maxindx[j].item())\n        if(torch.eq(maxindx[j],label[j])):\n            correct = correct +1\n        total = total+1\nprint(correct,total)\n#plt.plot(testgraph)\naccuracy = (correct/total)*100\nfscore = f1_score(cl2,pl2,average='macro')\nprint(\"F1 score is {0:.2f}\".format(fscore))\nprint('Accuracy is {0:.2f}%'.format(accuracy))\n","metadata":{"execution":{"iopub.status.busy":"2022-11-15T02:12:34.379482Z","iopub.status.idle":"2022-11-15T02:12:34.380257Z","shell.execute_reply.started":"2022-11-15T02:12:34.379992Z","shell.execute_reply":"2022-11-15T02:12:34.380019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN model\nI am utilizing the knn method of classification on these images by first putting on the images and their labels into seperate list. I will then put these list into sklearn's knn function.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\nfrom sklearn.neighbors import KNeighborsClassifier\ntrans = torchvision.transforms.Compose([\n    torchvision.transforms.RandAugment(),\n    torchvision.transforms.Resize(size =(512,512)),\n    ToTensor()\n])\ndata2 = torchvision.datasets.ImageFolder('../input/wild-animals/Wild_animals_512',transform = trans)\ntrain_data2,test_data2 = torch.utils.data.random_split(data2,[round(data2.__len__()*0.6),round(data2.__len__()*0.4)])\nvalid_data2,testy_data2 = torch.utils.data.random_split(test_data2,[345,344])\nimages  = []\nlabs = []\nvalidImages = []\nvalidlabs = []\nfor i in range(len(train_data2)):\n    pics, label = train_data2[i]\n    pics = pics.numpy()\n    images.append(pics.flatten())\n    labs.append(label)\n    \n# print(len(valid_data2))\nfor j in range(len(valid_data2)):\n    pics,label = valid_data2[j]\n    pics = pics.numpy()\n    validImages.append(pics.flatten())\n    validlabs.append(label)\nmodelKnn = KNeighborsClassifier(n_neighbors=20)\nmodelKnn.fit(images,labs)\nprint(modelKnn.score(validImages,validlabs)*100)\n\n\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-15T02:32:37.499399Z","iopub.execute_input":"2022-11-15T02:32:37.500102Z","iopub.status.idle":"2022-11-15T02:33:54.760524Z","shell.execute_reply.started":"2022-11-15T02:32:37.500065Z","shell.execute_reply":"2022-11-15T02:33:54.759347Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/PIL/Image.py:993: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n","output_type":"stream"},{"name":"stdout","text":"0.24057971014492754\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}