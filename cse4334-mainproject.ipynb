{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# !pip uninstall torch_xla\n# !pip3 install https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torch_xla-1.10-cp38-cp38-linux_x86_64.whl\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport time\nimport torchvision\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\n#References from documentation\nstart = time.time()\ntrans = torchvision.transforms.Compose([\n    torchvision.transforms.RandAugment(),\n    torchvision.transforms.AutoAugment(),\n#     torchvision.transforms.RandomHorizontalFlip(p=0.5)\n    torchvision.transforms.RandomEqualize(p=0.5),\n    torchvision.transforms.RandomVerticalFlip(p=0.5),\n    torchvision.transforms.RandomInvert(p=0.5),\n    torchvision.transforms.Resize(size =(200,200)),\n    ToTensor()\n])\nbatchS = 100\ndata = torchvision.datasets.ImageFolder('../input/wild-animals/Wild_animals_512',transform = trans)\ntrain_data,test_data = torch.utils.data.random_split(data,[round(data.__len__()*0.6),round(data.__len__()*0.4)])\n\n#valid_data,testy_data = torch.utils.data.random_split(test_data,[round(test_data.__len__()*0.5),round(test_data.__len__()*0.5)])\nvalid_data,testy_data = torch.utils.data.random_split(test_data,[345,344])\ntrain_load = DataLoader(train_data,shuffle = True,batch_size= batchS,drop_last=True)\nvalid_load = DataLoader(valid_data,shuffle = True,batch_size= batchS,drop_last = True)\ntest_load = DataLoader(testy_data,shuffle = True,batch_size= batchS,drop_last = True)\n# print(len(test_load.dataset))\n\nprint('done')\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-28T14:47:13.687988Z","iopub.execute_input":"2022-11-28T14:47:13.689166Z","iopub.status.idle":"2022-11-28T14:47:13.795009Z","shell.execute_reply.started":"2022-11-28T14:47:13.689012Z","shell.execute_reply":"2022-11-28T14:47:13.794000Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_20/3768729616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# !pip uninstall torch_xla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# !pip3 install https://storage.googleapis.com/tpu-pytorch/wheels/tpuvm/torch_xla-1.10-cp38-cp38-linux_x86_64.whl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_xla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_xla'"],"ename":"ModuleNotFoundError","evalue":"No module named 'torch_xla'","output_type":"error"}]},{"cell_type":"code","source":"#Neural Network referenced from  https://pytorch.org/tutorials/beginner/examples_nn/polynomial_module.html\n%matplotlib inline\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score\n\n#Initial Model code referenced from https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n#Code from the 'Define the Network' section\n#Experiment 1\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        #Feature extraction\n        self.conv= nn.Conv2d(3,64,9)\n        self.conv2 = nn.Conv2d(64,128,5)\n        self.conv3 = nn.Conv2d(128,256,5)\n        self.conv4 = nn.Conv2d(256,512,5)\n        self.conv5 = nn.Conv2d(512,1024,5)\n        self.bat2d1 = nn.BatchNorm2d(64)\n        self.bat2d2 = nn.BatchNorm2d(128)\n        self.bat2d3 = nn.BatchNorm2d(256)\n        self.bat2d4 = nn.BatchNorm2d(512)\n        self.bat2d5 = nn.BatchNorm2d(1024)\n        self.bat1d = nn.BatchNorm1d(196)\n        self.bat1d2 = nn.BatchNorm1d(256)\n#         self.bat1d3 = nn.BatchNorm1d(512)\n        self.dropout = nn.Dropout(p= 0.8)\n        self.dropout2 = nn.Dropout(p=0.5)\n\n        \n        #Classification layer\n        self.lin = nn.Linear(1024*2*2,196)\n        self.lin3 = nn.Linear(196,256)\n#         self.lin4 = nn.Linear(256,512)\n        self.lin2 = nn.Linear(256,6)\n        \n    def forward(self,x):\n        #First two lines are referenced\n        x = F.max_pool2d(F.relu(self.conv(x)),(2,2))\n        x=self.bat2d1(x)\n        self.dropout(x)\n        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n        x=self.bat2d2(x)\n        self.dropout(x)\n        x = F.max_pool2d(F.relu(self.conv3(x)),(2,2))\n        x=self.bat2d3(x)\n        self.dropout(x)\n        x = F.max_pool2d(F.relu(self.conv4(x)),(2,2))\n        x=self.bat2d4(x)\n        self.dropout(x)\n        x = F.max_pool2d(F.relu(self.conv5(x)),(2,2))\n        x=self.bat2d5(x)\n        self.dropout(x)\n#         print(x.shape)\n        #Flattening tensors\n        x = torch.flatten(x,1)\n#         print(x.shape)\n        x = F.relu(self.lin(x))\n        self.bat1d(x)\n        x= F.relu(self.lin3(x))\n        self.bat1d2(x)\n        self.dropout2(x)\n#         x= F.relu(self.lin4(x))\n#         self.bat1d3(x)\n#         self.dropout2(x)\n        x = F.softmax(self.lin2(x),dim = 1)\n        return x\n    \nmodel = Model()\ndevice = xm.xla_device()\n# device = torch.device(\"cuda:0\")\n# model.to(torch.device(\"cuda:0\"))\n# if torch.cuda.device_count() > 1:\n#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n#   # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n#     model = nn.DataParallel(model)\n\nmodel.to(device)\noptimizer = optim.SGD(model.parameters(), lr = 0.01,weight_decay=0.0000000001)\nlossfn = nn.CrossEntropyLoss()\nlossx = 0\nlossxt = 0\nl1 = 0\n\n#count = []\nlossgraph = []\ntestgraph = []\n#Code referenced from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n#I extracted data from the DataLoaders following the tutorial above\n#I used two for loops and called the optimizer and loss functions in a similar way\n#From the 'Define the network' section of the webpage.\nfor epoch in range(600):\n    print(epoch)\n    \n    for i,data in enumerate(train_load, 0):\n        lossx = 0\n        pics, label = data\n#         pics, label = pics.cuda(), label.cuda()\n        pics,label = pics.to(device),label.to(device)\n        \n        #print(pics.shape)\n        optimizer.zero_grad()\n        output = model(pics)\n        #reshaping label\n        #label = torch.tensor(label)\n        labely = torch.zeros(batchS,6)\n        for j in range(batchS):\n            labely[j][label[j]] = 1\n        #print(output)\n#         labely = labely.cuda()\n        labely = labely.to(device)\n#         https://stackoverflow.com/questions/58172188/how-to-add-l1-regularization-to-pytorch-nn-model\n       \n#         for param in model.parameters():\n#             l1 += param.abs().sum()\n        loss = lossfn(output,labely) \n        #lossgraph.append(loss)\n        loss.backward()\n        lossx += loss\n        #print(output)\n        optimizer.step()\n        #graphing loss\n        \n        #print(len(lossgraph),epoch,i)\n    lossgraph.append(lossx.item())\n\n    testingloss = nn.CrossEntropyLoss()\n#     classes = {0:'Motorbikes',1:'Airplanes',2:'Schooner'}\n    total = 0\n    correct = 0\n    for i, data in enumerate(valid_load,0):\n        lossxt = 0\n        pics,label = data\n#         pics, label = pics.cuda(), label.cuda()\n        pics,label = pics.to(device),label.to(device)\n        #print(pics.shape)\n        output = model(pics)\n        labely = torch.zeros(batchS,6)\n        for j in range(batchS):\n            labely[j][label[j]] = 1\n            #print(output)\n#         labely = labely.cuda()\n        labely = labely.to(device)\n        loss = testingloss(output,labely)\n        lossxt += loss.item()\n        #print(output)\n        maxele,maxindx = torch.max(output,1)\n        for j in range(batchS):\n#             print('Prediction: {0}, Answer: {1}'.format(classes[maxindx[j].item()],classes[label[j].item()]))\n            #print(maxindx[j].item(),label[j].item())\n            if(torch.eq(maxindx[j],label[j])):\n                correct = correct +1\n            total = total+1\n    #print(correct,total)\n    \n    #plt.legend('Training set','Validation set')\n    accuracy = (correct/total)*100\n    #print('Accuracy is {0:.2f}%'.format(accuracy))\n    testgraph.append(lossxt)\n\n        #plt.ylim(4e-1,7e-1)\n#plt.yscale('log')\n#plt.figure(figsize = (1,1))\n#print(testgraph)\n\n#plt.yscale('log')\n\n\n\ntorch.cuda.empty_cache()\n        \n        \n    \n\n\n\n    \n#for epoch,data in enumerate(train_load,0):\n    #inputy, label= data\n    #forward(inputy)\n#ask how to get gradient of linear stuff and how to determine convolutions","metadata":{"execution":{"iopub.status.busy":"2022-11-28T08:51:52.085601Z","iopub.status.idle":"2022-11-28T08:51:52.085864Z","shell.execute_reply.started":"2022-11-28T08:51:52.085722Z","shell.execute_reply":"2022-11-28T08:51:52.085739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.yscale('log')\nplt.plot(testgraph,'r-')\nplt.plot(lossgraph)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T08:51:52.086952Z","iopub.status.idle":"2022-11-28T08:51:52.087216Z","shell.execute_reply.started":"2022-11-28T08:51:52.087071Z","shell.execute_reply":"2022-11-28T08:51:52.087088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#validation cell\n#Code referenced from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n#I extracted data from the DataLoaders following the tutorial above\n#I used two for loops and called the optimizer and loss functions in a similar way\n#From the 'Define the network' section of the webpage.\n'''\n\n'''\n#testgraph = []\n#testingloss = nn.CrossEntropyLoss()\ntotal = 0\ncorrect = 0\ncl = []\npl = []\nfor i, data in enumerate(valid_load,0):\n    lossxt = 0\n    pics,label = data\n#     pics, label = pics.cuda(), label.cuda()\n    pics,label = pics.to(device),label.to(device)\n    #print(pics.shape)\n    output = model(pics)\n    labely = torch.zeros(batchS,6)\n    for j in range(batchS):\n        labely[j][label[j]] = 1\n        #print(output)\n#     labely = labely.cuda()\n    #loss = testingloss(output,labely)\n    #lossxt += loss.item()\n    #print(output)\n    maxele,maxindx = torch.max(output,1)\n    #testgraph.append(lossxt)\n    for j in range(batchS):\n#         print('Prediction: {0}, Answer: {1}'.format(classes[maxindx[j].item()],classes[label[j].item()]))\n        print(maxindx[j].item(),label[j].item())\n        cl.append(label[j].item())\n        pl.append(maxindx[j].item())\n        if(torch.eq(maxindx[j],label[j])):\n            correct = correct +1\n            print('Yay')\n        total = total+1\nprint(correct,total)\n#plt.plot(testgraph)\n#plt.legend('Training set','Validation set')\naccuracy = (correct/total)*100\nfscore = f1_score(cl,pl,average='macro')\nprint(\"F1 score is {0:.2f}\".format(fscore))\nprint('Accuracy is {0:.2f}%'.format(accuracy))\nstop = time.time()\nprint(f'time is {stop-start}')\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-28T08:51:52.088220Z","iopub.status.idle":"2022-11-28T08:51:52.088508Z","shell.execute_reply.started":"2022-11-28T08:51:52.088346Z","shell.execute_reply":"2022-11-28T08:51:52.088367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing data\n#Code referenced from https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n#I extracted data from the DataLoaders following the tutorial above\n#I used two for loops and called the optimizer and loss functions in a similar way.\n#From the 'Define the network' section of the webpage.\ntotal = 0\ncorrect =0\ncl2 = []\npl2 = []\nfor i2, data2 in enumerate(test_load,0):\n    #lossxt = 0\n    pics,label = data2\n#     pics, label = pics.cuda(), label.cuda()\n    pics,label = pics.to(device),label.to(device)\n    #print(pics.shape)\n    output = model(pics)\n    labely = torch.zeros(batchS,3)\n    for j in range(batchS):\n        labely[j][label[j]] = 1\n        #print(output)\n#     labely = labely.cuda()\n#     loss = testingloss(output,labely)\n    #lossxt += loss\n    #print(output)\n    maxele,maxindx = torch.max(output,1)\n    #testgraph.append(lossxt)\n    for j in range(batchS):\n        #print('Prediction: {0}, Answer: {1}'.format(classes[maxindx[j].item()],classes[label[j].item()]))\n        #print(maxindx[j].item(),label[j].item())\n        cl2.append(label[j].item())\n        pl2.append(maxindx[j].item())\n        if(torch.eq(maxindx[j],label[j])):\n            correct = correct +1\n        total = total+1\nprint(correct,total)\n#plt.plot(testgraph)\naccuracy = (correct/total)*100\nfscore = f1_score(cl2,pl2,average='macro')\nprint(\"F1 score is {0:.2f}\".format(fscore))\nprint('Accuracy is {0:.2f}%'.format(accuracy))\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T08:51:52.089377Z","iopub.status.idle":"2022-11-28T08:51:52.089634Z","shell.execute_reply.started":"2022-11-28T08:51:52.089499Z","shell.execute_reply":"2022-11-28T08:51:52.089515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN model\nI am utilizing the knn method of classification on these images by first putting on the images and their labels into seperate list. I will then put these list into sklearn's knn function.","metadata":{}},{"cell_type":"code","source":"#https://medium.com/swlh/image-classification-with-k-nearest-neighbours-51b3a289280\n'''\nPCA takes too long\nindividual histograms using numpy is 24%\nhistograms using cv2 library: 35 %\n'''\nfrom pathlib import Path\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image\nfrom skimage.io import imread\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import normalize\nimport cv2\nimport time\nimport skimage.io\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score\ntrans = torchvision.transforms.Compose([\n    torchvision.transforms.RandAugment(),\n    torchvision.transforms.Resize(size =(32,32)),\n    ToTensor()\n])\nstart = time.time()\nil = np.empty((1723,1))\nil = []\nlabe = [] \nvalidlabe = []\ntestlabs = []\nindex = np.random.choice(1723,1723)\nprint(len(index))\n#https://pyimagesearch.com/2016/08/08/k-nn-classifier-for-image-classification/\ndef extract_color_histogram(image,bins=(8,8,8)):\n    hsv = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n    hist = cv2.calcHist([hsv], [0,1,2],None,bins,[0,180,0,256,0,256])\n    cv2.normalize(hist,hist)\n    return hist.flatten()\np = Path('../input/wild-animals/Wild_animals_512')\nparameters = {'n_neighbors':[100,500], 'weights':('uniform','distance'),'leaf_size':[30,100],'p':(1,2)}\nfolders = [d for d in p.iterdir() if d.is_dir()]\nclasses = [d.name for d in folders]\ncounter =0\nfor i,direc in enumerate(folders):\n    for file in direc.iterdir():\n        img = cv2.imread(str(file))\n        cv2.resize(img,(32,32))\n        tot =  extract_color_histogram(img)\n        #https://datacarpentry.org/image-processing/05-creating-histograms/\n        histogramr, bin_edges = np.histogram(img[:,:0], bins=256, range=(0, 1))\n        histogramg, bin_edges = np.histogram(img[:,:1], bins=256, range=(0, 1))\n        histogramb, bin_edges = np.histogram(img[:,:0], bins=256, range=(0, 1))\n        tot= np.concatenate((histogramr,histogramg,histogramb))\n#         blue,red,green = cv2.split(img)\n        \n#         pca_Blue = PCA(n_components = 20)\n#         new_b = pca_Blue.fit_transform(blue)\n#         np.array(new_b)\n#         normalize(new_b)\n#         new_b = np.ndarray.flatten(new_b)\n        \n#         pca_R = PCA(n_components = 20)\n#         new_r = pca_R.fit_transform(red)\n#         np.array(new_r)\n#         normalize(new_r)\n#         new_r = np.ndarray.flatten(new_r)\n        \n#         pca_G = PCA(n_components = 20)\n#         new_g = pca_G.fit_transform(green)\n#         np.array(new_g)\n#         normalize(new_g)\n#         new_g = np.ndarray.flatten(new_g)\n#         tot = np.concatenate((new_r,new_g,new_b))\n#         print(np.shape(con))\n        il.append(tot)\n        labe.append(str(direc))\n#     print(il)\n# normalize(il)\n# print(np.shape(il))\nitest = []\nilabel = []\nfor i in range(1723):\n    itest.append(il[index[i]])\n    ilabel.append(labe[index[i]])\n        \ndata2 = torchvision.datasets.ImageFolder('../input/wild-animals/Wild_animals_512',transform = trans)\ntrain_data2,test_data2 = torch.utils.data.random_split(data2,[round(data2.__len__()*0.6),round(data2.__len__()*0.4)])\nvalid_data2,testy_data2 = torch.utils.data.random_split(test_data2,[345,344])\nimages  = []\nlabs = []\nvalidImages = []\nvalidlabs = []\nfeatureExtractor = nn.Sequential(\n\n        nn.Conv2d(3,64,9),\n        nn.ReLU()\n)\n#featureExtractor.to(torch.device('cuda:0'))\nfor i in range(len(train_data2)):\n    pics, label = train_data2[i]\n#     pics = pics.cuda()\n#     pics = featureExtractor(pics)\n#     images.append(pics.flatten().numpy())\n    labs.append(label)\n    \n# print(len(valid_data2))\nfor j in range(len(valid_data2)):\n    pics,label = valid_data2[j]\n#     pics = pics.cuda()\n#     pics = featureExtractor(pics)\n#     validImages.append(pics.flatten().numpy())\n    validlabs.append(label)\n\nprint('Doing knn now')\nprint(len(il))\ncorrect = 0\ntotal = 0\nmodelKnn = KNeighborsClassifier(n_neighbors = 200)\ngrid = GridSearchCV(modelKnn,parameters)\nprint(np.shape(itest[:1034]),np.shape(np.array(ilabel)),np.shape(itest[1035:1380]))\n\nmodelKnn.fit(itest[:1034],ilabel[:1034])\n\nfor i in range(len(validlabs)):\n    pred = modelKnn.predict(itest[1035+i].reshape(1,-1))\n    if pred == ilabel[1035+i]:\n        print('Yay')\n        correct+=1\n    total += 1\n#     print(f'Actual is {ilabel[1035+i]} and predicted is {pred}')\naccuracy = (correct/total)*100\nstop = time.time()\nprint(f'Training time is {stop-start}')\nprint(accuracy)\ncorrect = 0\ntotal = 0\naccuracy = (correct/total)*100\nc = []\npre = []\nfor i in range(len(testabs)):\n    pred = modelKnn.predict(itest[1380+i].reshape(1,-1))\n    pre.append(pred)\n    c.append(ilabel[1380+i])\n    if pred == ilabel[1380+i]:\n        print('Yay')\n        correct+=1\n    total += 1\n#     print(f'Actual is {ilabel[1035+i]} and predicted is {pred}')\naccuracy = (correct/total)*100\nstop = time.time()\nprint(f'Training time is {stop-start}')\nprint('test accuracy is ',accuracy)\nprint('f1 score is ',f1_score(c,pre,average='macro'))\n\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-24T12:53:21.714494Z","iopub.status.idle":"2022-11-24T12:53:21.715340Z","shell.execute_reply.started":"2022-11-24T12:53:21.715034Z","shell.execute_reply":"2022-11-24T12:53:21.715072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cell for visualizing a color histogram\n#https://docs.opencv.org/4.x/d1/db7/tutorial_py_histogram_begins.html\nimg = cv2.imread('../input/wild-animals/Wild_animals_512/fox-resize-512/00000001_512resized.png')\ncolor = ('b','g','r')\nfor i,col in enumerate(color):\n    histr = cv2.calcHist([img],[i],None,[256],[0,256])\n    plt.plot(histr,color = col)\n    plt.xlim([0,256])","metadata":{"execution":{"iopub.status.busy":"2022-11-24T12:53:21.716892Z","iopub.status.idle":"2022-11-24T12:53:21.717821Z","shell.execute_reply.started":"2022-11-24T12:53:21.717519Z","shell.execute_reply":"2022-11-24T12:53:21.717547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree Classifier","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n'''\nRandomForest = 35%\nDecisionTree = 24% with visualization\n'''\n#22% for raw pixels\n# 30 % after convolutions\n# Adapted from https://scikit-learn.org/stable/modules/tree.html#tree\nfrom sklearn.datasets import load_iris\nfrom sklearn import tree\nimport graphviz \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import f1_score\nfrom matplotlib.pyplot import imshow\nimport numpy as np\nimport os\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\nparameters = {'criterion':('gini','entropy'), 'splitter':('best','random')}\nimages = []\nvalidImages = []\ntestImages=[]\ntestlabs = []\nclasses = []\nlabs = []\nvalidlabs = []\nfeatureExtractor = nn.Sequential(\n\n        nn.Conv2d(3,64,9),\n        nn.ReLU(),\n#         nn.BatchNorm2d(64),\n        nn.MaxPool2d(2),\n        nn.Conv2d(64,128,3),\n        nn.ReLU(),\n#         nn.BatchNorm2d(128),\n        nn.MaxPool2d(2),\n        nn.Conv2d(128,256,3),\n        nn.ReLU(),\n#         nn.BatchNorm2d(),\n        nn.MaxPool2d(2)\n        \n)\npath = '../input/wild-animals/Wild_animals_512'\ntrans = torchvision.transforms.Compose([\n    torchvision.transforms.RandAugment(),\n    torchvision.transforms.Resize(size =(32,32)),\n    ToTensor()\n])\ndata2 = torchvision.datasets.ImageFolder('../input/wild-animals/Wild_animals_512',transform = trans)\ntrain_data2,test_data2 = torch.utils.data.random_split(data2,[round(data2.__len__()*0.6),round(data2.__len__()*0.4)])\nvalid_data2,testy_data2 = torch.utils.data.random_split(test_data2,[345,344])\nfor i in range(len(train_data2)):\n    pics, label = train_data2[i]\n    images.append(featureExtractor(pics).detach().flatten().numpy())\n    labs.append(label)\n    \n# print(len(valid_data2))\nfor j in range(len(valid_data2)):\n    pics,label = valid_data2[j]\n    validImages.append(featureExtractor(pics).detach().flatten().numpy())\n    validlabs.append(label)\nfor j in range(len(testy_data2)):\n    pics,label = testy_data2[j]\n    testImages.append(featureExtractor(pics).detach().flatten().numpy())\n    testlabs.append(label)\n# for direc in os.listdir(path):\n#     for file in os.listdir(os.path.join(path,direc)):\n        \n#         i = cv2.imread(os.path.join(path,direc,file),cv2.COLOR_BGR2RGB)\n#         i = cv2.normalize(i,i)\n#         i = cv2.resize(i,(32,32))\n        \n#         np.array(i)\n#         i = np.ndarray.flatten(i)\n        \n#         i = np.ndarray.tolist(i)\n# #         print(np.shape(i))\n#         images.append(i)\n#         classes.append(direc)\n# print(images)\n# print(classes) \n# temp = list(zip(images,classes))\n# np.random.shuffle(temp)\n# images,classes = zip(*temp)\n# np.random.shuffle(images)\nclf = DecisionTreeClassifier(criterion='entropy')\ngrid = GridSearchCV(clf,parameters)\nclf.fit(images,labs)\ntree.plot_tree(clf)\nprint(clf.score(validImages,validlabs))\ncorrect = 0\ntotal = 0\nfor i in range(len(validlabs)):\n    pred = clf.predict(np.array(validImages[i]).reshape(1,-1))\n    if pred == validlabs[i]:\n        correct +=1\n    total += 1\n    print('Actual: {0}, Predicted: {1}'.format(validlabs[i],pred))\naccuracy = (correct/total)*100\nprint(accuracy)\ncorrect = 0\ntotal = 0\nc = []\npre = []\nfor i in range(len(testlabs)):\n    pred = clf.predict(np.array(testImages[i]).reshape(1,-1))\n    pre.append(pre)\n    c.append(testlabs[i])\n    if pred == testlabs[i]:\n        correct +=1\n    total += 1\n    print('Actual: {0}, Predicted: {1}'.format(testlabs[i],pred))\naccuracy = (correct/total)*100\nprint('test accuracy',accuracy)\nprint('f1 score: ',f1_score(c,pre,average = 'macro'))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-24T12:53:21.719552Z","iopub.status.idle":"2022-11-24T12:53:21.720422Z","shell.execute_reply.started":"2022-11-24T12:53:21.720108Z","shell.execute_reply":"2022-11-24T12:53:21.720137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naive-Bayes Classifier","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import f1_score\nfrom matplotlib.pyplot import imshow\nimport numpy as np\nimport os\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\n\nfeatureExtractor = nn.Sequential(\n\n        nn.Conv2d(3,64,9),\n        nn.ReLU(),\n#         nn.BatchNorm2d(64),\n        nn.MaxPool2d(2),\n        nn.Conv2d(64,128,3),\n        nn.ReLU(),\n#         nn.BatchNorm2d(128),\n        nn.MaxPool2d(2),\n        nn.Conv2d(128,256,3),\n        nn.ReLU(),\n#         nn.BatchNorm2d(),\n        nn.MaxPool2d(2)\n        \n)\ntrans = torchvision.transforms.Compose([\n    torchvision.transforms.RandAugment(),\n    torchvision.transforms.Resize(size =(32,32)),\n    ToTensor()\n])\ndata2 = torchvision.datasets.ImageFolder('../input/wild-animals/Wild_animals_512',transform = trans)\ntrain_data2,test_data2 = torch.utils.data.random_split(data2,[round(data2.__len__()*0.6),round(data2.__len__()*0.4)])\nvalid_data2,testy_data2 = torch.utils.data.random_split(test_data2,[345,344])\nlabs = []\nimages = []\nvalidImages = []\nvalidlabs = []\ntestImages = []\ntestlabs = []\n\nfor i in range(len(train_data2)):\n    pics, label = train_data2[i]\n    images.append(featureExtractor(pics).detach().flatten().numpy())\n    labs.append(label)\n    \n# print(len(valid_data2))\nfor j in range(len(valid_data2)):\n    pics,label = valid_data2[j]\n    validImages.append(featureExtractor(pics).detach().flatten().numpy())\n    validlabs.append(label)\nfor j in range(len(testy_data2)):\n    pics,label = testy_data2[j]\n    testImages.append(featureExtractor(pics).detach().flatten().numpy())\n    testlabs.append(label)\nnbModel = GaussianNB()\nnbModel.fit(images,labs)\nprint(nbModel.score(validImages,validlabs))\ncorrect = 0\ntotal = 0\nfor i in range(len(validlabs)):\n    pred = nbModel.predict(np.array(validImages[i]).reshape(1,-1))\n    if pred == validlabs[i]:\n        print('Yippee ka yay!')\n        correct +=1\n    total += 1\n#     print('Actual: {0}, Predicted: {1}'.format(validlabs[i],pred))\naccuracy = (correct/total)*100\nprint(accuracy)\ncorrect = 0\ntotal = 0\nc= []\npre = []\nfor i in range(len(testlabs)):\n    pred = nbModel.predict(np.array(testImages[i]).reshape(1,-1))\n    pre.append(pred)\n    c.append(testlabs[i])\n    if pred == testlabs[i]:\n        print('Yippee ka yay!')\n        correct +=1\n    total += 1\n#     print('Actual: {0}, Predicted: {1}'.format(validlabs[i],pred))\naccuracy = (correct/total)*100\nprint(accuracy)\nprint('f1 score:', f1_score(c,pred,average = 'macro'))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T12:53:21.722109Z","iopub.status.idle":"2022-11-24T12:53:21.722935Z","shell.execute_reply.started":"2022-11-24T12:53:21.722637Z","shell.execute_reply":"2022-11-24T12:53:21.722664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Support Vector Classifier","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport os\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn as nn\nimport time\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score\nfrom sklearn.svm import SVC\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import ToTensor\n\nstart = time.time()\ntrans = torchvision.transforms.Compose([\n    torchvision.transforms.RandAugment(),\n    torchvision.transforms.Resize(size =(32,32)),\n    ToTensor()\n])\n\ndata2 = torchvision.datasets.ImageFolder('../input/wild-animals/Wild_animals_512',transform = trans)\ntrain_data2,test_data2 = torch.utils.data.random_split(data2,[round(data2.__len__()*0.6),round(data2.__len__()*0.4)])\nvalid_data2,testy_data2 = torch.utils.data.random_split(test_data2,[345,344])\n\nlabs = []\nimages = []\nvalidImages = []\nvalidlabs = []\ntestImages = []\ntestlabs = []\n\nfeatureExtractor = nn.Sequential(\n\n        nn.Conv2d(3,64,9),\n        nn.ReLU(),\n#         nn.BatchNorm2d(64),\n        nn.MaxPool2d(2),\n        nn.Conv2d(64,128,3),\n        nn.ReLU(),\n#         nn.BatchNorm2d(128),\n        nn.MaxPool2d(2),\n        nn.Conv2d(128,256,3),\n        nn.ReLU(),\n#         nn.BatchNorm2d(),\n        nn.MaxPool2d(2)\n        \n)\n\nfor i in range(len(train_data2)):\n    pics, label = train_data2[i]\n    images.append(featureExtractor(pics).detach().flatten().numpy())\n    labs.append(label)\n    \n# print(len(valid_data2))\nfor j in range(len(valid_data2)):\n    pics,label = valid_data2[j]\n    validImages.append(featureExtractor(pics).detach().flatten().numpy())\n    validlabs.append(label)\n    \nfor j in range(len(testy_data2)):\n    pics,label = testy_data2[j]\n    testImages.append(featureExtractor(pics).detach().flatten().numpy())\n    testlabs.append(label)\nsvcModel = SVC(C = 1000000,kernel = 'rbf',degree = 3,gamma= 'auto')\nparameters = {'C':[10E-5,10E5],'kernel':['poly','rbf','sigmoid'],'degree':[3,5],'gamma':['scale','auto']}\ngrid = GridSearchCV(svcModel,parameters)\nsvcModel.fit(images,labs)\nprint(svcModel.score(validImages,validlabs)*100)\ncorrect = 0\ntotal = 0\nfor i in range(len(validlabs)):\n    pred = svcModel.predict(np.array(validImages[i]).reshape(1,-1))\n    if pred == validlabs[i]:\n        print('Yippee ka yay!')\n        correct +=1\n    total += 1\n#     print('Actual: {0}, Predicted: {1}'.format(validlabs[i],pred))\naccuracy = (correct/total)*100\nstop = time.time()\nprint(accuracy)\n# print(grid.best_params_)\nprint(f'Processing time is {stop-start} seconds')\ncorrect = 0\ntotal = 0\nc = []\npre = []\nfor i in range(len(testlabs)):\n    pred = svcModel.predict(np.array(testImages[i]).reshape(1,-1))\n    pre.append(pred)\n    c.append(testlabs[i])\n    if pred == testlabs[i]:\n        print('Yippee ka yay!')\n        correct +=1\n    total += 1\n#     print('Actual: {0}, Predicted: {1}'.format(validlabs[i],pred))\naccuracy = (correct/total)*100\nprint(accuracy)\nprint('f1 score:', f1_score(c,pred,average = 'macro'))\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T12:53:21.724581Z","iopub.status.idle":"2022-11-24T12:53:21.725405Z","shell.execute_reply.started":"2022-11-24T12:53:21.725116Z","shell.execute_reply":"2022-11-24T12:53:21.725143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize svm\n%matplotlib inline\nh = 0.02\n#https://scikit-learn.org/0.18/auto_examples/svm/plot_iris.html\nx_min, x_max = np.array(images[:, 0]).min() - 1, np.array(images[:, 0]).max() + 1\ny_min, y_max = np.array(labs[:, 1]).min()- 1, np.array(labs[:, 1]).max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ = svcModel.predict(np.c_[xx.ravel(), yy.ravel()])\n\n\n    # Put the result into a color plot\nZ = Z.reshape(xx.shape)\nplt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n\n# Plot also the training points\nplt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm)\nplt.xlabel('Sepal length')\nplt.ylabel('Sepal width')\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\nplt.xticks(())\nplt.yticks(())\nplt.title('RBF SVC for images of wild animals')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-11-24T12:53:21.727089Z","iopub.status.idle":"2022-11-24T12:53:21.728053Z","shell.execute_reply.started":"2022-11-24T12:53:21.727723Z","shell.execute_reply":"2022-11-24T12:53:21.727751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}